## overall setup for big jobs

# (optional) generate samples
# split the list of samples into manageable sets: estimate from AnalTime and number of samples how long the job will take
# set up directories for each subset, including the pbs script
# (optional) submit them to the queue

# [A different script will put them back together]

## first try, assume we are just given big list of samples

import sys, os, os.path, re

files_we_need = ["runjob.pbs.template", "PeregrineClusterAllocator.py", "sampler.py", "openaero.py",
                 "design_load_case.py",	"opendakota.py","distn_input.py","openruniec.py", "simplemc.py","dlcproto-files.txt",
                 "turbsim_template.inp"]
dirs_we_need = ["ModelFiles", "InputFilesToWrite", "windwavedistn"]

def split_input(options):
    base = options.samples_file
    lines=file(base).readlines()
    incr = options.incr
    hdr = lines[0].strip()
    cnt = 1
    fno = 0

    print "splitting %s into files with no more than %d samples" % (base, incr)

    all_files = []
    while (cnt < len(lines)):
        fname = "%s.%d" % (base, fno)
        fout = file(fname, "w")
        fout.write("%s\n" % hdr)
        thiscnt = 0
        while (cnt < len(lines) and thiscnt < incr):
            ln = lines[cnt].strip()
            fout.write("%s\n" % ln)
            cnt += 1
            thiscnt += 1
        fout.close()
        all_files.append(fname)
        fno += 1

    return all_files

def get_filenames(options):
    # use "sample_files" to find list of input files to set up; one per line of intput
    lines = file(options.samples_file).readlines()
    all_files = []
    for ln in lines:
        all_files.append(ln.strip())
    return all_files


def write_pbs(fname, fno, est_time_hrs):
    lines = file("runjob.pbs.template").readlines()
    newlines = []
    for ln in lines:
        hstr = "%d" % est_time_hrs
        ln = re.sub(r'<hours>', hstr, ln)
        ln = re.sub(r'<sfile>', fname, ln)
        resname = "dlcproto.out.%d" % fno
        ln = re.sub(r'<resname>', resname, ln)
        newlines.append(ln)
    pbs = file("runjob.pbs", "w")
    for ln in newlines:
        pbs.write(ln)
    pbs.close()

def setup_dirs(all_sample_files, options):
    numfiles = len(all_sample_files)
    rootdir = os.path.abspath(options.run_dir_root)
    # create directories and copy stuff
    savedir = os.getcwd()
    all_dirnames  = []
    all_outnames = []
    for i in range(numfiles):
        fname  = all_sample_files[i]
        dirname = os.path.join(rootdir,"%s.dir" % fname)
        if not os.path.exists(dirname):
            os.makedirs(dirname)
        all_dirnames.append(dirname)
        all_outnames.append(os.path.join(dirname, "dlcproto.out"))

        for f in files_we_need:
            os.system("cp %s %s" % (f, dirname))
        for d in dirs_we_need:
            os.system("cp -r %s %s" % (d, dirname))
        os.system("cp %s %s" % (fname, dirname))
        # pbs template should have been copied.insert command to run
        os.chdir(dirname)
        write_pbs(fname, i, options.jobtime)        
        os.chdir(savedir)
    return all_outnames


def get_options():
    from optparse import OptionParser
    parser = OptionParser()    
    parser.add_option("-s", "--sample_file", dest="samples_file",  type="string", default="dlcproto-samples.txt",
                                    help="main input file describing cases to run")
    parser.add_option("-i", "--incr", dest="incr", help="samples per run", type="int", default=1000)
    parser.add_option("-d", "--dir", dest="run_dir_root",  type="string", default="../runs/",
                                    help="root directory for tree of runs (e.g. /scratch/pgraf/runiec/proto/runs/)")
    parser.add_option("-m", "--multiple", dest="multiple", help="setup for multiple input files instead of splitting one file", action="store_true", default=False)
    parser.add_option("-t", "--walltime", dest="jobtime", help="jobtime to request in pbs, in hours", type="int", default=10)
    
    (options, args) = parser.parse_args()
    return options, args


def write_collection_script(output_names, all_files, options):
    ## write shell script to simply copy the files back to 
    # dlcproto.out.0 ... dlcproto.out.<nruns>
    fout = file("collect_output.sh", "w")
    fout.write("#!/bin/bash\n\n")
    fout.write("# autogenerated file to copy outputs back to central location\n")
    if (not options.multiple):
        fout.write("# to get one big output file in root dir:\n")
        fout.write("#   ./collect_output.sh\n")
        fout.write("#   python stitchresults.py dlcproto.out %d %s.out\n" % (len(output_names), options.samples_file))
    else:
        fout.write(" to pull your results back to root dir:\n")
        fout.write("#   ./collect_output.sh\n")
                   
    for i in range(len(output_names)):
        name = output_names[i]
        sampname = all_files[i]
        if (not options.multiple):
            outpath = os.path.join(options.run_dir_root, "dlcproto.out.%d" % i)
        else:
            outpath  = os.path.join(options.run_dir_root, "%s.out" % sampname)
        fout.write("cp %s %s\n" % (name, outpath))
    fout.close()

def setup_jobs():
    options, arg = get_options()
    if (not options.multiple):
        # in root dir, split the main samples file
        all_files = split_input(options)
    else:
        all_files = get_filenames(options)

    # now setup directory for each
    all_output_names = setup_dirs(all_files, options)
    # write collection script
    write_collection_script(all_output_names, all_files, options)
    

if __name__=="__main__":
    setup_jobs()
